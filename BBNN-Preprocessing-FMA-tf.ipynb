{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ecf8c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from Utils import load, get_audio_path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "688e27e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file_path = '../Data/fma_metadata/tracks.csv'\n",
    "\n",
    "# Load the metadata file into a dataframe\n",
    "df = load(metadata_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53b8d98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_top</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Folk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Folk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         genre_top\n",
       "track_id          \n",
       "2          Hip-Hop\n",
       "5          Hip-Hop\n",
       "10             Pop\n",
       "140           Folk\n",
       "141           Folk"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = df['set', 'subset'] <= 'small'\n",
    "\n",
    "# Get the small dataset\n",
    "data = df.loc[small, ('track', 'genre_top')]\n",
    "data = data.to_frame()\n",
    "\n",
    "# Remove the multi-indexing from the created dataframe\n",
    "data = data.droplevel(level=0, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "195d1d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_top</th>\n",
       "      <th>relative_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>../Data/fma_small/000/000002.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>../Data/fma_small/000/000005.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pop</td>\n",
       "      <td>../Data/fma_small/000/000010.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Folk</td>\n",
       "      <td>../Data/fma_small/000/000140.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Folk</td>\n",
       "      <td>../Data/fma_small/000/000141.mp3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         genre_top                     relative_path\n",
       "track_id                                            \n",
       "2          Hip-Hop  ../Data/fma_small/000/000002.mp3\n",
       "5          Hip-Hop  ../Data/fma_small/000/000005.mp3\n",
       "10             Pop  ../Data/fma_small/000/000010.mp3\n",
       "140           Folk  ../Data/fma_small/000/000140.mp3\n",
       "141           Folk  ../Data/fma_small/000/000141.mp3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dir = \"../Data/fma_small\"\n",
    "data['relative_path'] = list(map((lambda x: get_audio_path(audio_dir, int(x))), data.index))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "856c3688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_top</th>\n",
       "      <th>relative_path</th>\n",
       "      <th>classID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>../Data/fma_small/000/000002.mp3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>../Data/fma_small/000/000005.mp3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pop</td>\n",
       "      <td>../Data/fma_small/000/000010.mp3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Folk</td>\n",
       "      <td>../Data/fma_small/000/000140.mp3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Folk</td>\n",
       "      <td>../Data/fma_small/000/000141.mp3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         genre_top                     relative_path  classID\n",
       "track_id                                                     \n",
       "2          Hip-Hop  ../Data/fma_small/000/000002.mp3        0\n",
       "5          Hip-Hop  ../Data/fma_small/000/000005.mp3        0\n",
       "10             Pop  ../Data/fma_small/000/000010.mp3        1\n",
       "140           Folk  ../Data/fma_small/000/000140.mp3        2\n",
       "141           Folk  ../Data/fma_small/000/000141.mp3        2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_types = list(data['genre_top'].unique())\n",
    "genre_to_classid = {genre:idx for idx, genre in enumerate(genres_types)}\n",
    "classid_to_genre = {idx:genre for idx, genre in enumerate(genres_types)}\n",
    "data['classID'] = [genre_to_classid[genre_top] for genre_top in data['genre_top'].values]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2f7cf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/fma_small/099/099134.mp3',\n",
       " '../Data/fma_small/108/108925.mp3',\n",
       " '../Data/fma_small/133/133297.mp3']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # NOT working files\n",
    "# data_dir = data['relative_path'].values\n",
    "# dirs = []\n",
    "# orig_path = \"../Data/fma_small/\"\n",
    "# for folder in os.listdir(orig_path):\n",
    "#     for file in os.listdir(orig_path+folder):\n",
    "#         dirs.append(orig_path+folder+\"/\"+file)\n",
    "# not_working_paths=[]\n",
    "# for real in data_dir:\n",
    "#     if real not in dirs:\n",
    "#         not_working_paths.append(real)\n",
    "\n",
    "# not_working_paths\n",
    "# not_working_paths = ['../Data/fma_small/099/099134.mp3', '../Data/fma_small/108/108925.mp3']\n",
    "# for path in not_working_paths:\n",
    "#     data = data[data['relative_path'] != path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42e6650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_csv, target_sr=22050):\n",
    "    \"\"\"\n",
    "    Load the waveform of the music and their corresponding labels\n",
    "    \n",
    "    Paramters:\n",
    "    ================================================\n",
    "    dataset_rootpath: string\n",
    "        The location of all the genres directories\n",
    "    \n",
    "    target_sr: int\n",
    "        The desired sample rate for all music\n",
    "    \n",
    "    Returns\n",
    "    =================================================\n",
    "    X: ndarray of shape (n_samples, 30 * target_size)\n",
    "        The waveform data of each music sample\n",
    "    \n",
    "    y: ndarray of shape(n_samples)\n",
    "        The label for each waveform       \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all genres names\n",
    "    X = []\n",
    "    y = []\n",
    "    samples = 0\n",
    "    \n",
    "    waveform_shape = 30 * target_sr\n",
    "    \n",
    "    print(\"Getting Data out...\")\n",
    "    \n",
    "    for file, class_id in tqdm(zip(data['relative_path'], data['classID'])):\n",
    "        \n",
    "        # Load the music file\n",
    "        audio, sr = librosa.load(file, sr=None)\n",
    "        \n",
    "        # Resample if it doesnt have the desired sr\n",
    "        if sr != target_sr:\n",
    "            audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
    "\n",
    "        # If it's less than the target shape -> padding with zeros\n",
    "        if len(audio) < waveform_shape:\n",
    "            audio = np.append(audio, np.zeros(shape=(waveform_shape - len(audio)), ))\n",
    "\n",
    "        # If it's more than the target shape -> truncate\n",
    "        if len(audio) > waveform_shape:\n",
    "            audio = audio[:waveform_shape]\n",
    "        \n",
    "        # Store the waveform and its label\n",
    "        X.append(audio)\n",
    "        y.append(class_id)\n",
    "        \n",
    "        samples += 1\n",
    "        \n",
    "        if samples % 100 == 0:\n",
    "            print('Already process %d music' % samples)\n",
    "\n",
    "    # Convert the waveforms and labels into ndarrays\n",
    "    return np.array(X, dtype=np.float32), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb38ec5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Data/fma_small/000/000002.mp3'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_working_paths = ['../Data/fma_small/099/099134.mp3',\n",
    "                 '../Data/fma_small/108/108925.mp3',\n",
    "                 '../Data/fma_small/133/133297.mp3']\n",
    "for path in not_working_paths:\n",
    "    data = data[data['relative_path'] != path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae2cf8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y):\n",
    "    \"\"\"\n",
    "    Convert an array of labels into their corresponding one hot encoding\n",
    "    \n",
    "    Parameters:\n",
    "    =========================================================\n",
    "    y: ndarray of shape (n_samples)\n",
    "        The labels of the dataset\n",
    "    \n",
    "    Returns:\n",
    "    =========================================================\n",
    "    y_onehot: ndarray of shape (n_sample, n_classes)\n",
    "        The one-hot encoded labels\n",
    "    \"\"\"\n",
    "    print(\"Encoding the labels...\")\n",
    "    y_onehot = []\n",
    "    \n",
    "    # get the each genre name\n",
    "    y_unique = sorted(set(y))\n",
    "    num_classes = len(y_unique)\n",
    "    for label in y:\n",
    "        \n",
    "        # Store an initial vector of zeros\n",
    "        cur = [0]*num_classes\n",
    "        \n",
    "        # Get the index of the label\n",
    "        encode_index = y_unique.index(label)\n",
    "        \n",
    "        # Store a one in the label index\n",
    "        cur[encode_index] = 1\n",
    "        \n",
    "        # Add the vector to the list\n",
    "        y_onehot.append(cur)\n",
    "        \n",
    "    # Convert the list to ndarray\n",
    "    return np.array(y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73e43a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspec_feature(X, target_sr, frame_size, hop_length, n_mels):\n",
    "    \"\"\"\n",
    "    Get the mel-spectrograms of an ndarray\n",
    "    \n",
    "    Parameters:\n",
    "    ============================================\n",
    "    X: ndarray of shape (n_samples, waveform_shape)\n",
    "        The waveform for each music sample\n",
    "    \n",
    "    target_sr: int\n",
    "        The sampling rate of the sample\n",
    "    \n",
    "    frame_size: int\n",
    "        The size of the frame window calculating the STFT\n",
    "    \n",
    "    hop_length: int\n",
    "        The overlapping between the frames\n",
    "    \n",
    "    n_mels: int\n",
    "        The number of frequency bands\n",
    "    \n",
    "    Returns:\n",
    "    ============================================\n",
    "    melspec_feature: ndarray of shape (n_samples, waveform_shape/hop_length, n_mels)\n",
    "        The extracted mel_spectrograms\n",
    "    \"\"\"\n",
    "    print('Extracting melspectrograms......')\n",
    "    melspec_feature = []\n",
    "    count = 0\n",
    "    for audio in X:\n",
    "        # Get the spectrogram for each audio\n",
    "        audio_melspec = librosa.feature.melspectrogram(audio, sr=target_sr, n_fft=frame_size, hop_length=hop_length)\n",
    "        \n",
    "        # Convert the spectrograms to mel-scale\n",
    "        audio_melspec = librosa.power_to_db(audio_melspec)\n",
    "        \n",
    "        # Transpose the spectrogram -> time(x)-frequeny(y)\n",
    "        audio_melspec = audio_melspec.T\n",
    "        \n",
    "        # Append the spectrograms to the list\n",
    "        melspec_feature.append(audio_melspec)\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "                print('Already process %d music' % count)\n",
    "                \n",
    "    # Convert the list into an ndarray\n",
    "    return np.array(melspec_feature, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49211eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Data out...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:39,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 100 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [03:23,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 200 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [05:07,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 300 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [06:46,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 400 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [08:32,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 500 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [10:15,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 600 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [11:58,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 700 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [13:40,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 800 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "900it [15:18,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 900 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [17:03,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 1000 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1100it [18:47,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 1100 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1200it [20:23,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 1200 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1300it [22:07,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 1300 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [23:53,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 1400 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1500it [25:37,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 1500 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1600it [27:21,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 1600 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1700it [29:06,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 1700 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1800it [30:48,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 1800 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1900it [32:31,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 1900 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [34:15,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 2000 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2100it [35:58,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 2100 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2200it [37:42,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 2200 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2300it [39:21,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 2300 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2400it [41:02,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 2400 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2500it [42:49,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 2500 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2600it [44:30,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 2600 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2700it [46:15,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 2700 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2800it [48:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 2800 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2900it [49:44,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 2900 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [51:27,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 3000 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3100it [53:06,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 3100 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3200it [54:48,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 3200 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3300it [56:28,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 3300 music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3371it [57:38,  1.02it/s]"
     ]
    }
   ],
   "source": [
    "target_sr = 22050\n",
    "frame_size = 2048\n",
    "hop_length = 1024\n",
    "n_mels = 128\n",
    "X, y = load_dataset(data, target_sr=target_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "699fa394",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onehot = one_hot_encoding(y)\n",
    "melspec_feature = get_melspec_feature(X, target_sr, frame_size, hop_length, n_mels)\n",
    "np.save('./Data/FMA_Processing/raw_labes.npy', y)\n",
    "np.save('./Data/FMA_Processing/onehot_labels.npy', y_onehot)\n",
    "np.save('./Data/FMA_Processing/raw_audio.npy', X)\n",
    "np.save('./Data/FMA_Processing/melspec_feature_2048.npy', melspec_feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
