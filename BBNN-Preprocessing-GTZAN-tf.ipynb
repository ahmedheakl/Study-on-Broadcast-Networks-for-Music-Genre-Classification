{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ecf8c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42e6650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_rootpath, target_sr=22050):\n",
    "    \"\"\"\n",
    "    Load the waveform of the music and their corresponding labels\n",
    "    \n",
    "    Paramters:\n",
    "    ================================================\n",
    "    dataset_rootpath: string\n",
    "        The location of all the genres directories\n",
    "    \n",
    "    target_sr: int\n",
    "        The desired sample rate for all music\n",
    "    \n",
    "    Returns\n",
    "    =================================================\n",
    "    X: ndarray of shape (n_samples, 30 * target_size)\n",
    "        The waveform data of each music sample\n",
    "    \n",
    "    y: ndarray of shape(n_samples)\n",
    "        The label for each waveform       \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all genres names\n",
    "    GENRES = sorted(os.listdir(dataset_rootpath))\n",
    "    X = []\n",
    "    y = []\n",
    "    samples = 0\n",
    "    \n",
    "    waveform_shape = 30 * target_sr\n",
    "    \n",
    "    # Iterate over all genres\n",
    "    for genre_index, genre in enumerate(GENRES):\n",
    "        label = genre_index + 1\n",
    "        genre_path = os.path.join(dataset_rootpath, genre)\n",
    "        \n",
    "        # Iterate over each song in the genre folder\n",
    "        for file in os.listdir(genre_path):\n",
    "            # Load the music file\n",
    "            audio, sr = librosa.load(os.path.join(genre_path, file), sr=None)\n",
    "            \n",
    "            # Resample if it doesnt have the desired sr\n",
    "            if sr != target_sr:\n",
    "                audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
    "                \n",
    "            # If it's less than the target shape -> padding with zeros\n",
    "            if len(audio) < waveform_shape:\n",
    "                audio = np.append(audio, np.zeros(shape=(waveform_shape - len(audio)), ))\n",
    "            \n",
    "            # If it's more than the target shape -> truncate\n",
    "            if len(audio) > waveform_shape:\n",
    "                audio = audio[:waveform_shape]\n",
    "                \n",
    "            # Store the waveform and its label\n",
    "            X.append(audio)\n",
    "            y.append(label)\n",
    "            samples += 1\n",
    "            if samples % 100 == 0 or samples == 999:\n",
    "                print('Already process %d music' % samples)\n",
    "                \n",
    "    # Convert the waveforms and labels into ndarrays\n",
    "    return np.array(X, dtype=np.float32), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae2cf8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y):\n",
    "    \"\"\"\n",
    "    Convert an array of labels into their corresponding one hot encoding\n",
    "    \n",
    "    Parameters:\n",
    "    =========================================================\n",
    "    y: ndarray of shape (n_samples)\n",
    "        The labels of the dataset\n",
    "    \n",
    "    Returns:\n",
    "    =========================================================\n",
    "    y_onehot: ndarray of shape (n_sample, n_classes)\n",
    "        The one-hot encoded labels\n",
    "    \"\"\"\n",
    "    print(\"Encoding the labels...\")\n",
    "    y_onehot = []\n",
    "    \n",
    "    # get the each genre name\n",
    "    y_unique = sorted(set(y))\n",
    "    num_classes = len(y_unique)\n",
    "    for label in y:\n",
    "        \n",
    "        # Store an initial vector of zeros\n",
    "        cur = [0]*num_classes\n",
    "        \n",
    "        # Get the index of the label\n",
    "        encode_index = y_unique.index(label)\n",
    "        \n",
    "        # Store a one in the label index\n",
    "        cur[encode_index] = 1\n",
    "        \n",
    "        # Add the vector to the list\n",
    "        y_onehot.append(cur)\n",
    "        \n",
    "    # Convert the list to ndarray\n",
    "    return np.array(y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73e43a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspec_feature(X, target_sr, frame_size, hop_length, n_mels):\n",
    "    \"\"\"\n",
    "    Get the mel-spectrograms of an ndarray\n",
    "    \n",
    "    Parameters:\n",
    "    ============================================\n",
    "    X: ndarray of shape (n_samples, waveform_shape)\n",
    "        The waveform for each music sample\n",
    "    \n",
    "    target_sr: int\n",
    "        The sampling rate of the sample\n",
    "    \n",
    "    frame_size: int\n",
    "        The size of the frame window calculating the STFT\n",
    "    \n",
    "    hop_length: int\n",
    "        The overlapping between the frames\n",
    "    \n",
    "    n_mels: int\n",
    "        The number of frequency bands\n",
    "    \n",
    "    Returns:\n",
    "    ============================================\n",
    "    melspec_feature: ndarray of shape (n_samples, waveform_shape/hop_length, n_mels)\n",
    "        The extracted mel_spectrograms\n",
    "    \"\"\"\n",
    "    print('Extracting melspectrograms......')\n",
    "    melspec_feature = []\n",
    "    count = 0\n",
    "    for audio in X:\n",
    "        # Get the spectrogram for each audio\n",
    "        audio_melspec = librosa.feature.melspectrogram(audio, sr=target_sr, n_fft=frame_size, hop_length=hop_length)\n",
    "        \n",
    "        # Convert the spectrograms to mel-scale\n",
    "        audio_melspec = librosa.power_to_db(audio_melspec)\n",
    "        \n",
    "        # Transpose the spectrogram -> time(x)-frequeny(y)\n",
    "        audio_melspec = audio_melspec.T\n",
    "        \n",
    "        # Append the spectrograms to the list\n",
    "        melspec_feature.append(audio_melspec)\n",
    "        count += 1\n",
    "        if count % 100 == 0 or count == 999:\n",
    "                print('Already process %d music' % count)\n",
    "                \n",
    "    # Convert the list into an ndarray\n",
    "    return np.array(melspec_feature, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49211eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 100 music\n",
      "Already process 200 music\n",
      "Already process 300 music\n",
      "Already process 400 music\n",
      "Already process 500 music\n",
      "Already process 600 music\n",
      "Already process 700 music\n",
      "Already process 800 music\n",
      "Already process 900 music\n",
      "Already process 999 music\n",
      "Encoding the labels...\n",
      "Extracting melspectrograms......\n",
      "Already process 100 music\n",
      "Already process 200 music\n",
      "Already process 300 music\n",
      "Already process 400 music\n",
      "Already process 500 music\n",
      "Already process 600 music\n",
      "Already process 700 music\n",
      "Already process 800 music\n",
      "Already process 900 music\n",
      "Already process 999 music\n"
     ]
    }
   ],
   "source": [
    "target_sr = 22050\n",
    "frame_size = 2048\n",
    "hop_length = 1024\n",
    "n_mels = 128\n",
    "dataset_rootpath = './Data/genres_original'\n",
    "X, y = load_dataset(dataset_rootpath, target_sr=target_sr)\n",
    "y_onehot = one_hot_encoding(y)\n",
    "melspec_feature = get_melspec_feature(X, target_sr, frame_size, hop_length, n_mels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "699fa394",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./Data/GTZAN_Processing/raw_labes.npy', y)\n",
    "np.save('./Data/GTZAN_Processing/onehot_labels.npy', y_onehot)\n",
    "np.save('./Data/GTZAN_Processing/raw_audio.npy', X)\n",
    "np.save('./Data/GTZAN_Processing/melspec_feature_2048.npy', melspec_feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
